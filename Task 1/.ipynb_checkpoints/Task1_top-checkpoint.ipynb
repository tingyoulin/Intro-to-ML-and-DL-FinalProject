{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 52971,
     "status": "ok",
     "timestamp": 1576586218515,
     "user": {
      "displayName": "Chin Hung Liu",
      "photoUrl": "",
      "userId": "17429209977804467644"
     },
     "user_tz": -480
    },
    "id": "FvlIv8nMu98o",
    "outputId": "63ca93e2-1817-4b62-a2f7-ad47db441451"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_VPaVGyil4gi"
   },
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "foW-KgLGlRCz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"drive/My Drive/Colab Notebooks/Final Project/Task 1/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_XJhFqSjwaqv"
   },
   "outputs": [],
   "source": [
    "traindf = df.sample(frac=0.75, random_state=777)   # 隨機將train.csv裡的檔案分成train:validation=3:1\n",
    "validf = df.drop(traindf.index)\n",
    "\n",
    "display(traindf.head())\n",
    "display(validf.head())\n",
    "print('各DataFrame 大小:', len(df), len(traindf), len(validf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ryPhGT8zw4ai"
   },
   "outputs": [],
   "source": [
    "testdf=pd.read_csv(\"drive/My Drive/Colab Notebooks/Final Project/Task 1/testName.csv\")\n",
    "testdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f5elrO8ilfgu"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# base_dir = '.\\\\train_img'\n",
    "# train_dir = os.path.join(base_dir, 'train_img')\n",
    "train_dir = 'drive/My Drive/Colab Notebooks/Final Project/Task 1/totalDepthPic'\n",
    "valid_dir = 'drive/My Drive/Colab Notebooks/Final Project/Task 1/totalDepthPic'\n",
    "test_dir = 'drive/My Drive/Colab Notebooks/Final Project/Task 1/totalDepthPic'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        rescale=1./255., \n",
    "        # validation_split=0.25\n",
    ")\n",
    "train_generator = train_datagen.flow_from_dataframe( \n",
    "    dataframe=traindf, \n",
    "    directory=train_dir, \n",
    "    x_col='Pic Name', \n",
    "    y_col='Total rebars', \n",
    "    has_ext=False, \n",
    "    # subset=\"training\", \n",
    "    class_mode=\"raw\", \n",
    "    batch_size=20,\n",
    "    target_size=(150, 150)\n",
    "    ) \n",
    "vaild_datagen = ImageDataGenerator(\n",
    "        rescale=1./255.\n",
    ")\n",
    "validation_generator = vaild_datagen.flow_from_dataframe( \n",
    "    dataframe=validf, \n",
    "    directory=valid_dir,\n",
    "    x_col='Pic Name', \n",
    "    y_col='Total rebars', \n",
    "    has_ext=False, \n",
    "    # subset=\"validation\", \n",
    "    class_mode=\"raw\",\n",
    "    batch_size=20,\n",
    "    target_size=(150, 150)\n",
    "    )\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255.)\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=testdf,\n",
    "    directory=test_dir,\n",
    "    x_col='Pic Name',\n",
    "    target_size=(150, 150),\n",
    "    color_mode='rgb',\n",
    "    shuffle=False,\n",
    "    class_mode=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dn_ES1BsbAHU"
   },
   "outputs": [],
   "source": [
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OdtXl0JF9cxx"
   },
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(150, 150, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Qk5zzB4bZoR"
   },
   "outputs": [],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pY5SLfcplfva"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def extract_features(generator, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    batch_size = generator.batch_size\n",
    "    # generator = datagen.flow_from_directory(\n",
    "    #     directory,\n",
    "    #     target_size=(150, 150),\n",
    "    #     batch_size=batch_size,\n",
    "    #     class_mode='binary')\n",
    "    i = 0\n",
    "\n",
    "    if generator.class_mode is None:\n",
    "      for inputs_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i : (i + features_batch.shape[0])] = features_batch   # 避免最後一個batch的shape不合\n",
    "        i += features_batch.shape[0]\n",
    "        if i >= sample_count:\n",
    "          # Note that since generators yield data indefinitely in a loop,\n",
    "          # we must `break` after every image has been seen once.\n",
    "          break\n",
    "      return features\n",
    "    else:\n",
    "      for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        # features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        features[i : (i + features_batch.shape[0])] = features_batch   # 避免最後一個batch的shape不合\n",
    "        # labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        labels[i : (i + features_batch.shape[0])] = labels_batch\n",
    "        i += features_batch.shape[0]\n",
    "        if i >= sample_count:\n",
    "          break\n",
    "    print()\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_generator, train_generator.samples)\n",
    "validation_features, validation_labels = extract_features(validation_generator, validation_generator.samples)\n",
    "test_features = extract_features(test_generator, test_generator.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KCTOrpf1lf3n"
   },
   "outputs": [],
   "source": [
    "train_features = np.reshape(train_features, (train_generator.samples, 4 * 4 * 512))\n",
    "validation_features = np.reshape(validation_features, (validation_generator.samples, 4 * 4 * 512))\n",
    "test_features = np.reshape(test_features, (test_generator.samples, 4 * 4 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1vGPBqi8lf-V"
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation='relu', input_dim=4 * 4 * 512))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "# model.add(layers.Dense(512, activation='relu'))\n",
    "# model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(1, activation=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M2Qi3me7b6dn"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "                  loss='mse',\n",
    "                  metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kDzDzETKt10v"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_features, train_labels,\n",
    "                    epochs=100,\n",
    "                    batch_size=20,\n",
    "                    validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ckZ-4DlvlgEy"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# acc = history.history['acc']\n",
    "# val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss)+1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wRdxm7bUlSKu"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(test_features)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1650,
     "status": "ok",
     "timestamp": 1575989093382,
     "user": {
      "displayName": "林亭佑",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCa4KdkqST8f-rHXHm_rjYPP9hYtgmAqB7qaLgX=s64",
      "userId": "15671635726506356258"
     },
     "user_tz": -480
    },
    "id": "tlhQcepJlSpe",
    "outputId": "5ef120fd-0c14-40ce-d513-1d0b5942239b"
   },
   "outputs": [],
   "source": [
    "pred_int = pred.astype('int')\n",
    "testdf['Total rebars'] = pred_int\n",
    "testdf.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NGz9SuTNvrg7"
   },
   "outputs": [],
   "source": [
    "testdf.to_csv(\"drive/My Drive/Colab Notebooks/Final Project/Task 1/Result/result18.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('task1_1219.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Task1_top.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
